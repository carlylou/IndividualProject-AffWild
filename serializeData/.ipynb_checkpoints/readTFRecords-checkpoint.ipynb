{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read TFRecords from tfrecord files and check the data format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFRecordsFiles(tfRecordsPath):\n",
    "    files = os.listdir(tfRecordsPath)\n",
    "    drop = filter(lambda x: x.startswith('.'), files)\n",
    "    for item in drop:\n",
    "        files.remove(item)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of tfrecords files, return ??????\n",
    "def read_from_tfrecord(tfRecordsFile):\n",
    "    print 'enter read_from_tfrecord'\n",
    "    # Created a feature\n",
    "    feature = {\n",
    "                    'frameNo': tf.FixedLenFeature([], tf.string),\n",
    "                   'frame': tf.FixedLenFeature([], tf.string),\n",
    "                  'valence': tf.FixedLenFeature([], tf.int64),\n",
    "                  'arousal': tf.FixedLenFeature([], tf.int64)\n",
    "              }\n",
    "    # Create a queue (filename_queue) to hold filenames:\n",
    "    # string_input_producer argument : capacity: An integer. Sets the queue capacity. \n",
    "    # shuffle's default value is True\n",
    "    # shuffling the filenames within an epoch if shuffle=True\n",
    "    filename_queue = tf.train.string_input_producer([tfRecordsFile], name = 'queue', \n",
    "                                                    num_epochs=NUM_EPOCHS, shuffle=True)\n",
    "    reader = tf.TFRecordReader()\n",
    "    print 'reader initialized'\n",
    "    # the reader returns the next record using: reader.read(filename_queue)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    print 'single_example_parsed'\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['frame'], tf.float32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [96, 96, 3])\n",
    "    # decode_raw output type do not have tf.string, only have some numerical type\n",
    "    frameNo = features['frameNo']\n",
    "    # Cast label data into int32\n",
    "    valence = tf.cast(features['valence'], tf.float32)\n",
    "    arousal = tf.cast(features['arousal'], tf.float32)\n",
    "    # Any preprocessing here ...\n",
    "\n",
    "    # VA value convert to [-1, 1] tensor operation\n",
    "    rangeV = tf.fill(tf.shape(valence), 1000.0)\n",
    "    valence = tf.div(valence, rangeV)\n",
    "    rangeA = tf.fill(tf.shape(arousal), 1000.0)\n",
    "    arousal = tf.div(arousal, rangeA)\n",
    "    # check frame number? But how?\n",
    "\n",
    "    # subtract mean value to images:? VGG FACE? tensor operation\n",
    "    image = tf.cast(image, tf.uint8)    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "    # images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, \n",
    "    # num_threads=1, min_after_dequeue=10)\n",
    "    print 'converted data type'\n",
    "    frameNos, images, valences, arousals = tf.train.batch([frameNo, image, valence, arousal], \n",
    "                                                      batch_size=BATCH_SIZE, num_threads=1)\n",
    "    print 'batch'\n",
    "    return frameNos, images, valences, arousals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of filenames\n",
    "def input_pipeline(sess):\n",
    "    tfRecordsPath = '/vol/bitbucket/ml9915/TFRecords/validation/'\n",
    "    tfRecordsFiles = getTFRecordsFiles(tfRecordsPath)\n",
    "    # read separate video data\n",
    "    filename = tfRecordsFiles[0]\n",
    "    frameNo, image, valence, arousal = read_from_tfrecord(tfRecordsPath+filename)\n",
    "    frameNo, image, valence, arousal = sess.run([frameNo, image, valence, arousal])\n",
    "    return frameNo, image, valence, arousal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Initialize all global and local variables\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Create a coordinator and run all QueueRunner objects\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "print 'start'\n",
    "tfRecordsPath = '/vol/bitbucket/ml9915/TFRecords/validation/'\n",
    "tfRecordsFiles = getTFRecordsFiles(tfRecordsPath)\n",
    "# read separate video data\n",
    "filename = tfRecordsFiles[0]\n",
    "frameNo, image, valence, arousal = read_from_tfrecord(tfRecordsPath+filename)\n",
    "for i in range(2):\n",
    "    print i\n",
    "    frameNos, images, valences, arousals = sess.run([frameNo, image, valence, arousal])\n",
    "    print len(frameNos), len(images), len(valences), len(arousals)\n",
    "# Stop the threads\n",
    "coord.request_stop()\n",
    "\n",
    "# Wait for threads to stop\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avenv2.7",
   "language": "python",
   "name": "venv-2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
